# Default values for vparking-settings.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
replicaCount: 3

# This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
commonTag: "v52"
image:
  repository: reagafonov/vparking-settings-arm64
  # This sets the pull policy for images.
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.

update: 
  repository: "reagafonov/vparking-settings-arm64-update"
  # This sets the pull policy for images.
  pullPolicy: IfNotPresent
  annotations: {
      helm.sh/hook-delete-policy: "before-hook-creation"
  }
  tag: "v63"

# This is for the secretes for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []
# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: { }
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# This is for setting Kubernetes Annotations to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
podAnnotations: { }
# This is for setting Kubernetes Labels to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
podLabels: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
service:
  # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
  type: ClusterIP
  # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
  port: 8080
  annotations: {
  }

# This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  enabled: true
  className: "nginx"
  annotations: {
    nginx.ingress.kubernetes.io/rewrite-target: /$1,
    kubernetes.io/ingress.class: nginx,
    nginx.ingress.kubernetes.io/use-regex: "true",
#    nginx.ingress.kubernetes.io/auth-url: "https://keycloak.keycloak.svc.cluster.local/realms/vparking/protocol/openid-connect/userinfo",
#    nginx.ingress.kubernetes.io/auth-signin: "https://keycloak/realms/vparking/protocol/openid-connect/auth?client_id=vparking&scope=openid+email+profile&state=CE3E1035-601F-47A0-AB99-C7D7B8D17881&nonce=62C9F9EC-2A58-4885-950C-7A74E45238CF&response_type=code&redirect_uri=http://arch.homework/settings/health",
    nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri",

    nginx.ingress.kubernetes.io/auth-url: "http://oauth2-proxy.oauth2-proxy.svc.cluster.local/oauth2/auth",
    nginx.ingress.kubernetes.io/auth-response-headers: "x-auth-request-user, x-auth-request-email, authorization",
    nginx.ingress.kubernetes.io/proxy-buffer-size: "16k"
    #nginx.ingress.kubernetes.io/auth-signin: "https://keycloak/auth-401"

  }
    # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: arch.homework
      paths:
        - pathRegexSuffix: /(.*)
          pathPrefix: /settings
          pathType: ImplementationSpecific
        
  tls: 
    - secretName: nginx-ingress-nginx-admission
      hosts:
        - oauth2-proxy.oauth2-proxy.svc.cluster.local

metricIngress:
  enabled: true
  className: "nginx"
  annotations: {
    nginx.ingress.kubernetes.io/rewrite-target: /$1,
    kubernetes.io/ingress.class: nginx,
    nginx.ingress.kubernetes.io/use-regex: "true",
  }
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: arch.homework
      paths:
        - pathRegexSuffix: /(.*)
          pathPrefix: /metrics/db
          pathType: ImplementationSpecific
          serviceName: db-metrics
          port:
            number: 9187
  
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  httpGet:
    path: /health
    port: http
readinessProbe:
  httpGet:
    path: /health
    port: http

# This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}

dbAuth:
  username: "keycloak1"
  password: 9ZuzN0KZHl
  postgresPassword: "postgres"
  server: "db"

prometheus:
  release: "monitoring"
monitoring:
  enabled: false
  
postgresql:
 
  auth:
    username: "keycloak1"
    password: 9ZuzN0KZHl
    postgresPassword: "postgres"
    enablePostgresUser: true

  passwordUpdateJob:
    enabled: false
  fullnameOverride: "db"
#  primary:
#    extendedConfiguration: |
#      shared_preload_libraries = 'pg_stat_statements'  
#       pg_stat_statements.max = 10000
#       pg_stat_statements.track = top
#  postgresqlSharedPreloadLibraries: "pgaudit, pg_stat_statements"
#  commonLabels: { release: "monitoring" }
#  metrics:
#    enabled:  false
#    customMetrics:
#      pg_database:
#        query: " SELECT pg_database.datname, pg_database_size(pg_database.datname) as size FROM pg_database"
#        metrics:
#          - datname:
#              usage: "LABEL"
#              description: "Name of the database"
#          - size:
#              usage: "GAUGE"
#              description: "Disk space used by the database"
#      pg_stat_statements:
#        query: "SELECT  queryid, datname, left(query, 100) as short_query, sum(calls) as calls, sum(total_plan_time+total_exec_time) as total_time, min(min_plan_time+min_exec_time) as min_time, max(max_plan_time+max_exec_time) as max_time, sum((mean_plan_time+mean_exec_time)*calls)/sum(calls) as mean_time FROM pg_stat_statements JOIN pg_database ON pg_stat_statements.dbid = pg_database.oid group by queryid, short_query, datname"
#        metrics:
#          - queryid:
#              usage: "LABEL"
#              description: "Query ID"
#          - datname:
#              usage: "LABEL"
#              description: "Database name"
#          - short_query:
#              usage: "LABEL"
#              description: "Query limited to 100 symbols"
#          - calls:
#              usage: "COUNTER"
#              description: "Number of times executed"
#          - total_time:
#              usage: "COUNTER"
#              description: "Total time spent in the statement, in milliseconds"
#          - min_time:
#              usage: "GAUGE"
#              description: "Minimum time spent in the statement, in milliseconds"
#          - max_time:
#              usage: "GAUGE"
#              description: "Maximum time spent in the statement, in milliseconds"
#      pg_stat_activity_connected:
#        query: "SELECT
#
#                  count(*) FILTER (WHERE state IS NOT NULL) AS total,
#
#                  count(*) FILTER (WHERE state = 'idle') AS idle,
#
#                  count(*) FILTER (WHERE state IN ('idle in transaction', 'idle in transaction (aborted)')) AS idle_in_xact,
#
#                  count(*) FILTER (WHERE state = 'active') AS active,
#
#                  count(*) FILTER (WHERE wait_event_type = 'Lock') AS waiting,
#
#                  count(*) FILTER (WHERE state IN ('fastpath function call','disabled')) AS others
#
#                  FROM pg_stat_activity WHERE backend_type = 'client backend'"
#        metrics:
#          - total:
#              usage: "GAUGE"
#              description: "The total number of connected clients and their states (active, idle in transaction, waiting)"
#          - idle:
#              usage: "GAUGE"
#              description: "Number of connected clients in idle state"
#          - idle_in_xact:
#              usage: "GAUGE"
#              description: "Number of connected clients in 'idle in transaction', 'idle in transaction (aborted) states"
#          - active:
#              usage: "GAUGE"
#              description: "Number of connected clients in 'Lock' state"
#          - waiting:
#              usage: "GAUGE"
#              description: "Number of connected clients in 'fastpath function call','disabled' states"
#          - others:
#              usage: "GAUGE"
#              description: "Number of connected clients in 'fastpath function call','disabled' states"
#
#      pg_stat_activity_xact:
#        query: "SELECT coalesce(max(extract(epoch FROM clock_timestamp() - xact_start)),0) AS max_idle_seconds FROM pg_stat_activity WHERE state IN ('idle in transaction', 'idle in transaction (aborted)')"
#        metrics:
#          - max_idle_seconds:
#              usage: "GAUGE"
#              description: "Longest idle transaction"
#      pg_stat_activity_client:
#        query: "SELECT coalesce(max(extract(epoch FROM clock_timestamp() - state_change)),0) AS max_idle_seconds FROM pg_stat_activity WHERE wait_event_type = 'Lock'"
#        metrics:
#          - max_idle_seconds:
#              usage: "GAUGE"
#              description: "Longest time when a client is in a waiting state."
#      pg_process_idle:
#        query: |
#          WITH
#            metrics AS (
#              SELECT
#                application_name,
#                SUM(EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change))::bigint)::float AS process_idle_seconds_sum,
#                COUNT(*) AS process_idle_seconds_count
#              FROM pg_stat_activity
#              WHERE state = 'idle'
#              GROUP BY application_name
#            ),
#            buckets AS (
#              SELECT
#                application_name,
#                le,
#                SUM(
#                  CASE WHEN EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change)) <= le
#                    THEN 1
#                    ELSE 0
#                  END
#                )::bigint AS bucket
#              FROM
#                pg_stat_activity,
#                UNNEST(ARRAY[1, 2, 5, 15, 30, 60, 90, 120, 300]) AS le
#              GROUP BY application_name, le
#              ORDER BY application_name, le
#            )
#          SELECT
#            application_name,
#            process_idle_seconds_sum as seconds_sum,
#            process_idle_seconds_count as seconds_count,
#            ARRAY_AGG(le) AS seconds,
#            ARRAY_AGG(bucket) AS seconds_bucket
#          FROM metrics JOIN buckets USING (application_name)
#          GROUP BY 1, 2, 3
#        metrics:
#          - application_name:
#              usage: "LABEL"
#              description: "Application Name"
#          - seconds:
#              usage: "HISTOGRAM"
#              description: "Idle time of server processes"
#
#    service:
#      ports:
#        metrics: 9187
#    serviceMonitor:
#      enabled: false
#      interval: 30s
#      scrapeTimeout: 10s
#      labels:
#        { release: "monitoring" }
#
#    
        

